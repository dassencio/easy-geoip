#!/usr/bin/env python
# -*- coding: utf-8 -*-


import os
import csv
import urllib
import shutil
import pickle
import zipfile

from config import *
from ipfunctions import *


# a database "enumeration" class
class Database:
	GeonameID4 = 0
	GeonameID6 = 1
	Location = 2


##
# @brief removes the current database and recreates its directory
#
def reset_database():

	if os.path.exists("database/"):
		print("Removing existing database")
		shutil.rmtree('database/', ignore_errors=True)

	os.makedirs("database/")


##
# @brief downloads a file pointed to by an URL
# @note the file is placed on the current directory (with the same name as
#       specified in the URL)
#
def download_file(url):

	filename = url.split('/')[-1]
	print("Downloading %s" % filename)

	urllib.urlretrieve (url, filename)


##
# @brief extracts all the files in a ZIP file and places them on the working
#        directory (the internal directory hierarchy of the ZIP file is
#        ignored)
#
def extract_zip(zipfilename):

	print("Decompressing %s" % zipfilename)
	with open(zipfilename, 'rb') as ziphandle:

		contents = zipfile.ZipFile(ziphandle)

		for filename in contents.namelist():
			print("  Extracting %s" % filename)
			output = open(filename.split("/")[-1], 'wb')
			output.write(contents.read(filename))
			output.close()

		ziphandle.close()


##
# @brief segments a database stored on a CSV file into small binary files
# @param filename the name of the CSV file
# @database the database type (one of the types in the Database class)
#
def segment_database(filename, dbtype):

	print("Breaking %s into small binary chunks" % filename)

	with open(filename, 'r') as csvfile:

		prefix = ("geoid-ip4", "geoid-ip6", "location")[dbtype]

		# build a database index too (target value -> segment number)
		index_filename = "database/index-%s" % prefix
		index_file = open(index_filename, 'wb')

		# open the database reader and skip the header row
		database = csv.reader(csvfile)
		next(database)

		row_num = 0
		segment_num = 0
		block = (ip4_block, ip6_block, geoid_block)[dbtype]

		# create/open the first database segment file
		segment_file = open("database/%s-%d" % (prefix, segment_num), 'wb')

		index_lower = 0
		for row in database:

			# for geoname ID databases, the first column is the
			# netmask and the second is its associated geoname ID
			if dbtype != Database.Location:

				(ip_lower,ip_upper) = netmask_to_ip_range(row[0])
				geoname_id = row[1]

				# ignore incomplete rows (no geoname ID)
				if geoname_id == "":
					continue

				segment_object = [ip_lower, ip_upper, int(geoname_id)]
				index_upper = ip_upper

			# for location databases, the first row contains the
			# geoname ID and the rest is geographical information
			else:
				geoname_id = int(row[0])
				segment_object = [geoname_id] + row[1:]
				index_upper = geoname_id

			pickle.dump(segment_object, segment_file)

			row_num += 1

			# if it is time to start a new segment file
			if row_num % block == 0:

				pickle.dump((index_lower, index_upper), index_file)
				index_lower = index_upper + 1
				segment_file.close()
				segment_num += 1

				# create/open the next database segment file
				segment_file = open("database/%s-%d" % (prefix,
				                    segment_num), 'wb')

		# if necessary, dump trailing index data
		if row_num % block != 0:
			pickle.dump((index_lower, index_upper), index_file)

		print("  Number of segments created: %d" % (segment_num+1))
		print("  Number of entries per segment: %d" % block)

		segment_file.close()
		index_file.close()
		csvfile.close()


##
# @brief removes all generated temporary files
#
def remove_temporary_files():

	print("Removing temporary files")

	for root, dirs, files in os.walk("./"):
		for filename in files:

			exts = ('.csv', '.zip', '.txt')
			if any(filename.lower().endswith(ext) for ext in exts):
				print("  Removing %s" % filename)
				os.remove(os.path.join(root, filename))


##
# @brief generates the geolocation database
#
def generate_database():

	reset_database()

	base_url = "http://geolite.maxmind.com/download/geoip/database/"
	download_file(base_url + "GeoLite2-City-CSV.zip")

	extract_zip("GeoLite2-City-CSV.zip")

	# break the geoname ID database into smaller segments
	# segment scheme: [lower IP, upper IP, gename ID]
	segment_database("GeoLite2-City-Blocks-IPv4.csv", Database.GeonameID4)
	segment_database("GeoLite2-City-Blocks-IPv6.csv", Database.GeonameID6)

	# break the city database into smaller segments
	# scheme: [geoname ID, locale code, continent code, continent name,
	#          country ISO code, country ISO name, subdivision 1 ISO_code,
	#          subdivision 1 name, subdivision 2 ISO code, subdivision 2
	#          name, city name, metro code, time zone]
	segment_database("GeoLite2-City-Locations-en.csv", Database.Location)

	remove_temporary_files()

	print("Done!")


if __name__ == '__main__':
	generate_database()


